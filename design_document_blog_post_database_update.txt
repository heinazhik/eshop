To support the "Blog" service, new tables need to be added to the database schema to store blog posts, categories, authors, and comments. Here’s the Python script to update the database schema:

Updated Database Schema Script for Blog Service
python
Copy
import psycopg2
from psycopg2 import sql

# Database connection details
DB_NAME = "ecommerce_db"
DB_USER = "your_username"
DB_PASSWORD = "your_password"
DB_HOST = "localhost"
DB_PORT = "5432"

# Connect to the ecommerce database
conn = psycopg2.connect(
    dbname=DB_NAME,
    user=DB_USER,
    password=DB_PASSWORD,
    host=DB_HOST,
    port=DB_PORT
)
conn.autocommit = True
cursor = conn.cursor()

# Create Blog_Categories table
try:
    cursor.execute("""
        CREATE TABLE Blog_Categories (
            category_id SERIAL PRIMARY KEY,
            name VARCHAR NOT NULL UNIQUE
        );
    """)
    print("Created Blog_Categories table!")
except psycopg2.Error as e:
    print(f"Error creating Blog_Categories table: {e}")

# Create Blog_Authors table
try:
    cursor.execute("""
        CREATE TABLE Blog_Authors (
            author_id SERIAL PRIMARY KEY,
            name VARCHAR NOT NULL,
            email VARCHAR UNIQUE NOT NULL,
            bio TEXT
        );
    """)
    print("Created Blog_Authors table!")
except psycopg2.Error as e:
    print(f"Error creating Blog_Authors table: {e}")

# Create Blog_Posts table
try:
    cursor.execute("""
        CREATE TABLE Blog_Posts (
            post_id SERIAL PRIMARY KEY,
            title VARCHAR NOT NULL,
            content TEXT NOT NULL,
            excerpt TEXT,
            author_id INTEGER REFERENCES Blog_Authors(author_id),
            category_id INTEGER REFERENCES Blog_Categories(category_id),
            published_at TIMESTAMP DEFAULT now(),
            updated_at TIMESTAMP DEFAULT now()
        );
    """)
    print("Created Blog_Posts table!")
except psycopg2.Error as e:
    print(f"Error creating Blog_Posts table: {e}")

# Create Blog_Comments table
try:
    cursor.execute("""
        CREATE TABLE Blog_Comments (
            comment_id SERIAL PRIMARY KEY,
            post_id INTEGER REFERENCES Blog_Posts(post_id),
            author_name VARCHAR NOT NULL,
            author_email VARCHAR NOT NULL,
            content TEXT NOT NULL,
            commented_at TIMESTAMP DEFAULT now()
        );
    """)
    print("Created Blog_Comments table!")
except psycopg2.Error as e:
    print(f"Error creating Blog_Comments table: {e}")

# Close the connection
cursor.close()
conn.close()

print("Database schema updated successfully to support Blog service!")
Explanation of Changes:
Blog_Categories Table:

Stores blog post categories (e.g., "Category 1", "Category 2").

Columns:

category_id: Primary key.

name: Category name (unique).

Blog_Authors Table:

Stores information about blog authors.

Columns:

author_id: Primary key.

name: Author's name.

email: Author's email (unique).

bio: Author's biography (optional).

Blog_Posts Table:

Stores blog posts.

Columns:

post_id: Primary key.

title: Post title.

content: Full post content.

excerpt: Short excerpt of the post.

author_id: Foreign key referencing Blog_Authors.

category_id: Foreign key referencing Blog_Categories.

published_at: Timestamp of when the post was published.

updated_at: Timestamp of when the post was last updated.

Blog_Comments Table:

Stores comments on blog posts.

Columns:

comment_id: Primary key.

post_id: Foreign key referencing Blog_Posts.

author_name: Name of the commenter.

author_email: Email of the commenter.

content: Comment content.

commented_at: Timestamp of when the comment was made.

Python Script to Populate the Blog Tables with Dummy Data
Here’s a Python script to populate the new blog-related tables with dummy data for testing:

python
Copy
import psycopg2
from psycopg2 import sql
from faker import Faker
import random

# Database connection details
DB_NAME = "ecommerce_db"
DB_USER = "your_username"
DB_PASSWORD = "your_password"
DB_HOST = "localhost"
DB_PORT = "5432"

# Initialize Faker
fake = Faker()

# Connect to the ecommerce database
conn = psycopg2.connect(
    dbname=DB_NAME,
    user=DB_USER,
    password=DB_PASSWORD,
    host=DB_HOST,
    port=DB_PORT
)
conn.autocommit = True
cursor = conn.cursor()

# Function to generate dummy blog categories
def generate_dummy_categories(num_categories=3):
    categories = ["Category 1", "Category 2", "Category 3"]
    for category in categories:
        cursor.execute("""
            INSERT INTO Blog_Categories (name)
            VALUES (%s);
        """, (category,))
    print(f"Inserted {len(categories)} blog categories!")

# Function to generate dummy blog authors
def generate_dummy_authors(num_authors=3):
    authors = []
    for _ in range(num_authors):
        author = {
            "name": fake.name(),
            "email": fake.email(),
            "bio": fake.text()
        }
        cursor.execute("""
            INSERT INTO Blog_Authors (name, email, bio)
            VALUES (%s, %s, %s);
        """, (author["name"], author["email"], author["bio"]))
        authors.append(author)
    print(f"Inserted {len(authors)} blog authors!")

# Function to generate dummy blog posts
def generate_dummy_posts(num_posts=5, num_authors=3, num_categories=3):
    posts = []
    for _ in range(num_posts):
        post = {
            "title": fake.sentence(),
            "content": fake.text(),
            "excerpt": fake.sentence(),
            "author_id": random.randint(1, num_authors),
            "category_id": random.randint(1, num_categories)
        }
        cursor.execute("""
            INSERT INTO Blog_Posts (title, content, excerpt, author_id, category_id)
            VALUES (%s, %s, %s, %s, %s);
        """, (post["title"], post["content"], post["excerpt"], post["author_id"], post["category_id"]))
        posts.append(post)
    print(f"Inserted {len(posts)} blog posts!")

# Function to generate dummy blog comments
def generate_dummy_comments(num_comments=10, num_posts=5):
    comments = []
    for _ in range(num_comments):
        comment = {
            "post_id": random.randint(1, num_posts),
            "author_name": fake.name(),
            "author_email": fake.email(),
            "content": fake.sentence()
        }
        cursor.execute("""
            INSERT INTO Blog_Comments (post_id, author_name, author_email, content)
            VALUES (%s, %s, %s, %s);
        """, (comment["post_id"], comment["author_name"], comment["author_email"], comment["content"]))
        comments.append(comment)
    print(f"Inserted {len(comments)} blog comments!")

# Generate and insert dummy data
generate_dummy_categories()
generate_dummy_authors()
generate_dummy_posts()
generate_dummy_comments()

# Close the connection
cursor.close()
conn.close()

print("Dummy blog data inserted successfully!")
How It Works:
Schema Update:

Adds new tables (Blog_Categories, Blog_Authors, Blog_Posts, Blog_Comments) to support the blog service.

Dummy Data:

Generates realistic dummy data for blog categories, authors, posts, and comments using the Faker library.

Testing:

Run the schema update script first to create the new tables.

Run the dummy data script to populate the tables with test data.

